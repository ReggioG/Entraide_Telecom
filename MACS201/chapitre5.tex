\subsection{$L^2$ processes}

	\begin{defn}
		The process $X = (X_t)_{t \in T}$ defined on $(\Omega,\mathcal{F},\proba)$ with values in $\C^d$ is an $L^2$ process if $\forall t \in T, X_t = L^2(\Omega,\mathcal{F},\proba)$.
		Its \textbf{mean function} is defined on $T$ by $\mu(t) = \esp(X_t)$ and the \textbf{covariance function} is defined on $T \times T$ by $\Gamma(s,t) = \Cov(X_s,X_t) = \esp \left( (X_s - \mu(s)) \herm{(X_t - \mu(t))} \right)$.
	\end{defn}

	\begin{pop}
		Let $\Gamma$ be the covariance function of a $L^2$ process $X = (X_t)_{t \in T}$ with values in $\C^d$.
		The following properties hold.
		\begin{enumerate}[(i)]
			\item Hermitian symmetry : $\forall s, t \in T, \Gamma(s,t) = \herm{\Gamma(t,s)}$.
			\item Nonnegativity : $\forall n \in \N^*, t_1,\ldots, t_n \in T, a_1, \ldots, a_n \in \C^d, \sum_{1 \leq k,m \leq n} \herm{a_k} \Gamma(t_k,t_m) a_m \geq 0$.
		\end{enumerate}
		Conversely, if $\Gamma$ satisfies these two properties, there exists an $L^2$ process with values in $\C^d$ with covariance function $\Gamma$.
	\end{pop}

	In the scalar case ($d = 1$), we also use he notation $\gamma(s,t)$.

\subsection{Weakly sationary processes}

	\begin{defn}
		Let $\mu \in \C^d$ and $\Gamma \colon \Z \to \C^{d \times d}$.
		A process $(X_t)_{t \in \Z}$ with values in $\C^d$ is said \textbf{weakly stationary} with mean $\mu$ and autocovariance function $\Gamma$ if all the following assertions hold:
		\begin{enumerate}[(i)]
			\item $X$ is an $L^2$ process, i.e. $\esp \left( \abs{X_t}^2 \right) < + \infty$,
			\item $\forall t \in \Z, \esp(X_t) = \mu$,
			\item $\forall (s,t) \in \Z \times \Z, \Cov(X_s,X_t) = \Gamma(s - t)$.
		\end{enumerate}
	\end{defn}

	A strictly stationary $L^2$ process is weakly stationary.

	\begin{pop}
		The autocovariance function $\gamma \colon \Z \to \C$ of a complex valued weakly stationary process satisfies the following:
		\begin{enumerate}[(i)]
			\item Hermition symmetry : $\forall s \in \Z, \gamma(-s) = \overline{\gamma(s)}$.
			\item Nonnegative definiteness : $\forall i \in \N^*, a_1, \ldots, a_n \in \C, \sum_{s = 1}^n \sum_{t = 1}^n \overline{a_s} \gamma(s - t) a-t \geq 0$.
		\end{enumerate}
	\end{pop}

	\begin{defn}
		Let $X$ be a weakly stationary process with autocovariance function $\gamma$ such that $\gamma(0) \neq 0$.
		The \textbf{autocorrelation function} of $X$ is defined as $\forall \tau \in \Z, \rho(\tau) = \frac{\gamma(\tau)}{\gamma(0)}$.
		It is normalized in the sense that $\rho(0) = 1$ and $\forall s \in \Z, \abs{\rho(s)} \leq 1$.
	\end{defn}

	\begin{defn}
		A \textbf{weak white noise} is a centered weakly stationary process whose autocovariance function satisfies $\gamma(0) = \sigma^2 > 0$ and $\forall s \neq 0, \gamma(s) = 0$.
		We will denote $(X_t) \sim \WN(0,\sigma^2)$.
		When a white noise is an i.i.d. process it is called a \textbf{strong white noise}.
		We will denote $(X_t) \sim \IID(0,\sigma^2)$.
	\end{defn}


\subsection{Spectral measure}

	\begin{thm}(Heglotz)
		A sequence $(\gamma(h))_{h \in \Z}$ is a nonnegative definite hermitian sequence iff there exists a finite nonnegative measure $\nu$ on $(\T,\mathcal{\T})$ such that
		$$\forall h \in \Z, \gamma(h) = \int_\T e^{ih \lambda} \nu(\diff \lambda)\ .$$
		Moreover this relation defines $\nu$ uniquely.
	\end{thm}

	\begin{rem}
		This applies to all autocovariance function of a weakly stationary process $X$.
		In this case $\nu$ is called the \textbf{spectral measure} of $X$.
		If $\nu$ admits a density $f$, it is called the \textbf{spectral density function}.
	\end{rem}

	\begin{cor}
		Let $(\gamma(h))_{h \in \Z} \in l^2(\Z)$.
		Then it is a nonnegative definite hermitian sequence iff for almost every $\lambda$, $f(\lambda) = \frac{1}{2\pi} \sum_{h \in \Z} \gamma(h) e^{-ih \lambda}$ is nonnegative, where the convergence holds in $L^2(\T)$.
	\end{cor}

	\begin{defn}
		A weakly stationary process $X$ is called \textbf{linearly predictable} if $\exists n \geq 1, \forall t \geq n, X_t \in \Span(X_1,\ldots,X_n)$ (in the $L^2$ sense).
	\end{defn}

	\begin{pop}
		Let $\gamma$ be the autocovariance function of a weakly stationary process $X$.
		If $\gamma(0) \neq 0$ and $\gamma(t) \overset{t \to \infty}{\to} 0$ then $X$ is not linearly predictable.
	\end{pop}

\subsection{Spectral representation of a weakly stationary process}

	\begin{defn}
		A \textbf{random fields with orthogonal increments} $W$ on $(\mathsf{X},\mathcal{X})$ is a $L^2$ random process indexed on $\mathcal{X}$, say $W = (W(A))_{A \in \mathcal{X}}$ such that
		\begin{enumerate}[(i)]
			\item $\forall A \in \mathcal{X}, \esp(W(A)) = 0$,
			\item $\forall A,B \in \mathcal{X}$ such that $A \cap B = \emptyset$, $W(A)$ and $W(B)$ are uncorrelated and $W(A \cup B) = W(A) + W(B)$,
			\item for all nonincreasing sequence $(A_n)_{n \in \N} \subset \mathcal{X}, \bigcap_{n = 0}^\infty A_n = \emptyset$, we have $\Var(W(A_n)) \to 0$.
		\end{enumerate}
	\end{defn}

	\begin{lem}
		Let $W$ a random field with orthogonal increments on $(\mathsf{X},\mathcal{X})$.
		Let $A \in \mathcal{X}$ and set $\nu(A) = \Var(W(A))$.
		Then $\nu$ is a finite nonnegative measure on $(\mathsf{X},\mathcal{X})$.
		Moreover $\forall A, B \in \mathcal{X}, \Cov(W(A),W(B)) = \nu(A \cap B)$.
	\end{lem}

	The measure $\nu$ is called the \textbf{intensity measure} of $W$.

	\begin{lem}
		Let $W$ be a $L^2$ random process indexed by $\mathcal{X}$ such that $\forall A \in \mathcal{X}, \esp(W(A)) = 0$.
		Suppose $\exists \nu, \forall A,B \in \mathcal{X}, \Cov(W(A),W(B)) = \nu(A \cap B)$.
		Then $W$ is a random field with orthogonal increments on with intensity measure $\nu$.
	\end{lem}

	\begin{thm}
		Let $W$ be a random field with orthgonal increments with intensity measure $\nu$.
		Then there exists a unique isometric operator $w$ from $L^2(\mathsf{X},\mathcal{X},\nu)$ to $L^2(\Omega,\mathcal{F},\proba)$ such that $\forall A \in \mathcal{X}, w(\indic_A) = W(A)$.
		For all $f \in L^2(\mathsf{X},\mathcal{X},\nu)$ we further have $\esp(w(f)) = 0$ and $w(L^2(\mathsf{X},\mathcal{X},\nu) = \overline{\Span}(W(A), A \in \mathcal{X})$.
	\end{thm}

	\begin{thm}
		Let $\nu$ be a finite nonnegative measure on $(\mathsf{X},\mathcal{X})$ and $J \colon L^2(\mathsf{X},\mathcal{X},\nu) \to L^2(\Omega,\mathcal{F},\proba)$ an isometric operator such that $\forall f, \esp(J(f)) = 0$.
		Then there exists a random field $W$ with orthogonal increments on $\mathsf{X}$ with intensity measure $\nu$ such that $\forall f, J(f) = \int_{\mathsf{X}} f \diff W$.
	\end{thm}

	\begin{pop}
		Let $W$ be a r.f.o.i. on $(\T,\mathcal{B}(\T))$ with intensity measure $\nu$.
		Then the sequence $(X_t)_{t \in \Z}$ defined by $X_t = \int_\T e^{it \lambda} \diff W(\lambda)$ is a centered weakly stationary process with spectral measure $\nu$.
	\end{pop}

	\begin{defn}
		Let $X$ be a $L^2$ process.
		Its \textbf{linear closure} is defined as $\mathcal{H}_{\infty}^X = \overline{\Span}(X_t, t \in \Z)$ (closure in $L^2(\Omega,\mathcal{F},\proba)$).
	\end{defn}

	\begin{thm}
		Let $X$ be a centered weakly stationary process with spectral measure $\nu$.
		Then there exists a r.f.o.i. $\Hat{X}$ on $(\T,\mathcal{B}(\T))$ with intensity measure $\nu$, called the \textbf{spectral field}, such that $\forall t \in \Z, X_t = \int e^{it \lambda} \diff \Hat{X}(\lambda)$.
		Moreover, the mapping $f \mapsto \int f \diff \Hat{X}$ defines the unique operator from $L^2(\T,\mathcal{B}(\T),\nu)$ to $\mathcal{H}_{\infty}^X$ that maps each function $\lambda \mapsto e^{it \lambda}$ to $X_t$.
	\end{thm}


\subsection{Innovation process}

	Let $X = (X_t)_{t \in \Z}$ denote a centered weakly stationary process.
	Let $\mathcal{H}_t^X = \overline{\Span}(X_s, s \leq t)$ denote the \textbf{linear past} of $X$ up to time $t$.

	\begin{defn}
		We call \textbf{innovation process} the process $\epsilon = (\epsilon_t)_{t \in \Z}$ defined by $\epsilon_t = X_t - \proj(X_t \mid \mathcal{H}_{t - 1}^X)$.
	\end{defn}

	\begin{defn}
		We call \textbf{predictor of order $p$} the random variable $\proj(X_t \mid \mathcal{H}_{t - 1,p}^X)$ and the \textbf{partial innovation process} of order $p$ the process $\epsilon_p^+ = (\epsilon_{t,p}^+)_{t \in \Z}$ defined by $\epsilon_{t,p}^+ = X_t - \proj(X_t \mid \mathcal{H}_{t - 1,p}^X)$.
		The \textbf{prediction coefficients} are any coefficients $\phi_p^+ = (\phi_{k,p}^+)_{k \in \iniff{1}{p}}$ which satisfy $\forall t \in \Z, \proj(X_t \mid \mathcal{H}_{t - 1,p}^X) = \sum_{k = 1}^p \phi_{k,p}^+ X_{t - k}$.
	\end{defn}
	
	\begin{cor}
		The innovation process of a centered weakly stationary process is a (centered) weak white noise.
		Its variance is called the \textbf{innovation variance} of the process.
	\end{cor}

	\begin{defn}
		If the variance of its innovation process is zero, we say that $X$ is \textbf{deterministic}.
		Otherwise we say that $X$ is \textbf{regular}.
	\end{defn}

	We define the intersection of the whole past of $X$ as $\mathcal{H}_{-\infty}^X = \bigcap_{t \in \Z} \mathcal{H}_t^X$.
	We denote $\psi_s = \frac{\scal{X_t}{\epsilon_{t - s}}}{\sigma^2}$.
	
	\begin{thm}[\textbf{Wold decomposition}]
		Let $X$ be a regular process, $\epsilon$ its innovation process and $\sigma^2$ its innovation variance, so that $\epsilon \sim \WN(0,\sigma^2)$.
		Define the $L^2$ centered process $U$ as $U_t = \sum_{k = 0}^\infty \psi_k \epsilon_{t - k}$.
		Define the $L^2$ centered process $V$ b $\forall t \in \Z, X_t = U_t + V_t$.
		Then the following assertions hold,
		\begin{enumerate}[(i)]
			\item $U_t = \proj(X_t \mid \mathcal{H}_t^\epsilon)$ and $V_t = \proj(X_t \mid \mathcal{H}_{-\infty}^X)$,
			\item $\epsilon$ and $V$ are uncorrelated: $\forall (t,s), \scal{V_t}{\epsilon_s} = 0$,
			\item $U$ is a purely non-dterministic process and has same innovation as $X$.
				Moreover $\forall t \in \Z, \mathcal{H}_t^\epsilon = \mathcal{H}_t^U$.
			\item $V$ is a deterministic process and $\mathcal{H}_{-\infty}^V = \mathcal{H}_{-\infty}^X$.
		\end{enumerate}
	\end{thm}
