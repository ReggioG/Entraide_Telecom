On note $\Omega$ l'univers et $\mathcal{F}$ la tribu des événements.
On considère une variable aléatoire $X$, appelée observation, définie sur $(\Omega, \mathcal{F})$ et à valeur dans l'espace des observations $(\mathcal{X}, \mathcal{B}(\mathcal{X}))$, ou $\mathcal{B}(\mathcal{X})$ est une tribu composée de parties de $\mathcal{X}$.

\begin{defn}
	\textbf{Modèle statistique} : famille de probabilités $\mathcal{P}$ sur $\mathcal{B}(\mathcal{X})$.
	Si $\Theta$ est un ensemble quelconque tel que $\mathcal{P} = \{ P_\theta, \theta \in \Theta \}$ alors $\Theta$ est appelé \textbf{espace des paramètres} du modèle.
\end{defn}

\begin{rem}
	L'existence d'une paramétrisation est toujours acquise, quitte à prendre $\Theta = \mathcal{P}$.
\end{rem}

Si $\Theta$ peut être choisi comme sous-ensemble d'un espace euclidien, le modèle est dit \textbf{paramétrique}.
Si $\Theta \subset \Theta_1 \times \Theta_2$ où $\Theta_1$ est inclus dans un espace euclidien, le modèle est dit \textbf{semi-paramétrique}.

\begin{defn}
	Une \textbf{statistique} est une variable aléatoire s'écrivant commme une fonction mesurable des observations, de type $\varphi(X)$ où $\varphi \colon (\mathcal{X}, \mathcal{B}(\mathcal{X})) \to (\R^d, \mathcal{B}(\R^d))$ est mesurable.
\end{defn}

\begin{defn}[Identifiabilité]
	Un modèle statistique $\mathcal{P}$ décrit par un paramètre $\theta \in \Theta$ est dit \textbf{identifiable} si $\theta \mapsto P_\theta$ est injective.
	Plus généralement, une fonction $g$ de $\theta$ est dite identifiable si $\left( P_{\theta_1} = P_{\theta_2} \right) \implies \left( g(\theta_1) = g(\theta_2) \right)$.
\end{defn}

\begin{rem}
	Avec $\Theta = \mathcal{P}$ on sait qu'il existe toujours au moins une paramétrisation identifiable.
\end{rem}

\begin{defn}
	Un modèle statistique est dit \textbf{dominé} s'il existe une mesure positive $\mu$ sur $\mathcal{B}(\mathcal{X})$ telle que pour tout $\theta \in \Theta$, $P_\theta \in \mathcal{P}$ admette une densité de probabilité $p_\theta$ par rapport à $\mu$.
\end{defn}

\begin{rem}
	Tout modèle défini sur un espace fini ou dénombrable $(\mathcal{X}, \mathcal{P}(\mathcal{X}))$ est dominé par la mesure de comptage sur $\mathcal{X}$, $\mu = \sum_{x \in \mathcal{X}} \delta_x$.
\end{rem}

\begin{defn}
	L'application $\theta \to p(x ; \theta)$ s'appelle la fonction de \textbf{vraisemblance} de l'observation $x$ (avec $p(\cdot; \theta)$, ou $p_\theta(\cdot)$ la densité de la loi $P_\theta$ par rapport à une mesure dominante de référence $\mu$).
\end{defn}

\begin{note}
	Pour parler de $n$ observations on notera une loi produit $P_n = P^{\otimes n}$ lorsque les échantillons sont i.i.d, et $\mathcal{P}_n = \{ P_n, P \in \mathcal{P} \}$ le modèle associé.
\end{note}

\begin{defn}
	Le type de réponse que l'on attend d'une \emph{procédure de décision} (procédure d'estimation ou test statistique) s'appelle une \textbf{action}.
	On notera $\mathcal{A}$ l'espace des actions.
	Une \textbf{règle de décision} est alors définie comme une fonction $\delta \colon \mathcal{X} \to \mathcal{A}$.
\end{defn}

\begin{defn}
	Soit $\delta \colon \mathcal{X} \to \mathcal{A}$ une règle de décision.
	Son \textbf{risque} sous la loi $P_\theta \in \mathcal{P}$ est $R(\theta,\delta) = \esp_\theta \left[ L(\theta, \delta(X)) \right] \in \bar{\R}_+$.
\end{defn}
